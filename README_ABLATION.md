# PROFILE Ablation Study - GPU Server Setup

## ğŸ¯ Overview

This repository contains the complete code for running PROFILE ablation experiments on a GPU server. The ablation study evaluates 5 configurations Ã— 2 attacks Ã— 3 seeds = **30 experiments** on MNIST with LeNet-5.

## ğŸ“¦ Repository Structure

```
.
â”œâ”€â”€ README_ABLATION.md              # This file
â”œâ”€â”€ requirements_gpu.txt            # Python dependencies
â”œâ”€â”€ setup_gpu_environment.sh        # Environment setup script
â”‚
â”œâ”€â”€ Core PROFILE System
â”‚   â”œâ”€â”€ PROFILE_server.py          # Main FL server with bucketing + HE + validators
â”‚   â”œâ”€â”€ Clean-client2.py           # FL client with attack support
â”‚   â”œâ”€â”€ cnn.py                     # LeNet-5 model definition
â”‚   â”œâ”€â”€ utils.py                   # Utility functions
â”‚   â”œâ”€â”€ federated_data_loader.py   # Data partitioning
â”‚   â”œâ”€â”€ load_covid.py              # MNIST data loading
â”‚   â”œâ”€â”€ strong_attacks.py          # MinMax and Fang attacks
â”‚   â””â”€â”€ detect.py                  # Detection utilities
â”‚
â”œâ”€â”€ Ablation Framework
â”‚   â”œâ”€â”€ run_single_ablation_experiment.py   # Run one experiment
â”‚   â”œâ”€â”€ run_all_30_experiments.sh           # Run all 30 experiments
â”‚   â”œâ”€â”€ ablation_metrics.py                 # Metrics collection
â”‚   â”œâ”€â”€ plot_ablation_results.py            # Analysis and visualization
â”‚   â””â”€â”€ test_ablation_setup.py              # Verification script
â”‚
â””â”€â”€ Documentation
    â”œâ”€â”€ ABLATION_STUDY_README.md     # Detailed user guide
    â”œâ”€â”€ INTEGRATION_GUIDE.py         # Integration instructions
    â””â”€â”€ START_HERE.md                # Quick start guide
```

## ğŸš€ Quick Setup on GPU Server

### Step 1: Clone Repository

```bash
# Clone from your private GitHub
git clone https://github.com/YOUR_USERNAME/profile-ablation.git
cd profile-ablation
```

### Step 2: Install xMK-CKKS Homomorphic Encryption

```bash
# Clone the xMK-CKKS library
git clone https://github.com/MetisPrometheus/rlwe-xmkckks.git
cd rlwe-xmkckks
pip install -e .
cd ..
```

### Step 3: Setup Python Environment

```bash
# Create conda environment with GPU support
conda create -n profile_gpu python=3.10 -y
conda activate profile_gpu

# Install PyTorch with CUDA (adjust for your CUDA version)
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# Install TensorFlow with GPU
pip install tensorflow[and-cuda]

# Install other dependencies
pip install -r requirements_gpu.txt
```

### Step 4: Verify GPU Access

```bash
# Check NVIDIA GPU
nvidia-smi

# Test PyTorch GPU
python -c "import torch; print(f'PyTorch CUDA available: {torch.cuda.is_available()}')"

# Test TensorFlow GPU
python -c "import tensorflow as tf; print(f'TensorFlow GPUs: {tf.config.list_physical_devices(\"GPU\")}')"
```

### Step 5: Verify Setup

```bash
# Run verification tests
python test_ablation_setup.py
```

Expected output: `âœ… All 6 tests pass`

## ğŸ® Running Experiments

### Option 1: Test Single Experiment (~1 hour)

```bash
conda activate profile_gpu

python run_single_ablation_experiment.py \
    --config A_Bucketing_Only \
    --attack label_flip \
    --seed 42
```

### Option 2: Run All 30 Experiments (30-50 hours)

```bash
conda activate profile_gpu

# Run in background with logging
nohup ./run_all_30_experiments.sh > ablation_run.log 2>&1 &

# Monitor progress
tail -f ablation_run.log

# Check GPU usage
watch -n 1 nvidia-smi
```

### Option 3: Run Experiments in Parallel (if multiple GPUs)

```bash
# Edit run_all_30_experiments.sh and add:
# export CUDA_VISIBLE_DEVICES=0  # For GPU 0
# Or run multiple instances on different GPUs

# Terminal 1 (GPU 0)
CUDA_VISIBLE_DEVICES=0 python run_single_ablation_experiment.py --config A_Bucketing_Only --attack label_flip --seed 42

# Terminal 2 (GPU 1)
CUDA_VISIBLE_DEVICES=1 python run_single_ablation_experiment.py --config B_Bucketing_DP --attack label_flip --seed 42
```

## ğŸ“Š After Experiments Complete

### Generate Analysis and Figures

```bash
# Find your results directory
ls -lh ablation_results_*/

# Run analysis
python plot_ablation_results.py ablation_results_YYYYMMDD_HHMMSS/
```

This generates:
- `ablation_table.csv` - Summary table
- `ablation_table.tex` - LaTeX table for manuscript
- `accuracy_label_flip.png` - Accuracy over rounds (label-flip attack)
- `accuracy_min_max.png` - Accuracy over rounds (min-max attack)
- `detection_f1.png` - Detection F1 scores bar chart
- `rebuttal_paragraph.txt` - Pre-written rebuttal text with numbers

## ğŸ” Experiment Configurations

| Config | Bucketing | HE | DP (Ïƒ) | Validators | Purpose |
|--------|-----------|----|---------|-----------|---------| 
| **A** Bucketing_Only | âœ… | âœ… | âŒ | âŒ | Baseline bucketing benefit |
| **B** Bucketing+DP | âœ… | âœ… | 0.01 | âŒ | Privacy-utility tradeoff |
| **C** Bucketing+Validators | âœ… | âœ… | âŒ | 5 per bucket | Detection effectiveness |
| **D** PROFILE_Full | âœ… | âœ… | 0.01 | 5 per bucket | Complete system |
| **E** FedAvg_Baseline | âŒ | âœ… | âŒ | âŒ | No-defense baseline |

### Attacks

- **Label-Flip**: Simple poisoning (t â†’ (t+1) % 10)
- **Min-Max**: Sophisticated scaled gradients (Î³=50)

### Parameters

- **Total Clients (K)**: 50
- **Clients per Round**: 10 (20% participation)
- **Malicious Clients**: 10 (20%, IDs 0-9)
- **Global Rounds**: 50
- **Dataset**: MNIST (LeNet-5)
- **Seeds**: 42, 123, 456

## ğŸ“ˆ Expected Results

Based on federated learning literature:

| Configuration | Test Accuracy | Attack Success | Detection F1 |
|---------------|---------------|----------------|--------------|
| E (FedAvg) | 20-40% | 60-80% | N/A |
| A (Bucketing) | 60-75% | 30-50% | N/A |
| B (+ DP) | 58-72% | 32-52% | N/A |
| C (+ Validators) | 70-80% | 15-25% | 0.70-0.85 |
| D (Full) | 68-78% | 17-27% | 0.68-0.82 |

## ğŸ› Troubleshooting

### GPU Out of Memory

```bash
# Reduce batch size in cnn.py (default: 32)
# Edit: batch_size = 16

# Or limit GPU memory growth
export TF_FORCE_GPU_ALLOW_GROWTH=true
```

### Connection Issues

```bash
# Check if ports are available
netstat -tuln | grep 8080

# Change server port if needed
python PROFILE_server.py --port 8081
```

### Environment Issues

```bash
# Verify all imports work
python -c "import flwr, tensorflow, torch, numpy, sklearn, matplotlib"

# Check rlwe_xmkckks
python -c "from rlwe_xmkckks import RLWE; print('xMK-CKKS OK')"
```

## ğŸ“ Important Notes

1. **GPU Memory**: Each experiment needs ~4-6 GB GPU memory. Monitor with `nvidia-smi`.

2. **Long Running**: Full ablation study takes 30-50 hours. Use `nohup` or `screen`:
   ```bash
   screen -S ablation
   ./run_all_30_experiments.sh
   # Detach: Ctrl+A, D
   # Reattach: screen -r ablation
   ```

3. **Checkpoint Saving**: Results are auto-saved after each experiment. Safe to interrupt and resume.

4. **Disk Space**: Each experiment generates ~500MB (metrics + checkpoints). Total: ~15GB.

## ğŸ” Private Repository

This repository is **private** and contains proprietary PROFILE implementation. Do not share without permission.

## ğŸ“§ Contact

For issues or questions about the ablation study, contact the PROFILE team.

## ğŸ¯ Next Steps After Results

1. âœ… Generate analysis figures
2. âœ… Review ablation_table.csv for numbers
3. âœ… Include LaTeX table in manuscript
4. âœ… Use rebuttal_paragraph.txt for reviewer response
5. âœ… Package reproducibility artifact (code + results + README)

---

**Last Updated**: November 23, 2025  
**PROFILE Version**: 1.0  
**Ablation Framework Version**: 1.0
